{"cells":[{"cell_type":"code","execution_count":10,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-05T09:32:41.616159Z","iopub.status.busy":"2023-09-05T09:32:41.615721Z","iopub.status.idle":"2023-09-05T09:32:41.621781Z","shell.execute_reply":"2023-09-05T09:32:41.620652Z","shell.execute_reply.started":"2023-09-05T09:32:41.616127Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-09-05T09:32:41.624775Z","iopub.status.busy":"2023-09-05T09:32:41.623617Z","iopub.status.idle":"2023-09-05T09:33:04.675384Z","shell.execute_reply":"2023-09-05T09:33:04.674165Z","shell.execute_reply.started":"2023-09-05T09:32:41.624732Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set shape: (80000, 8)\n","Validation set shape: (10000, 8)\n","Test set shape: (10000, 8)\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Assuming you have an Excel file named 'customer_churn_large_dataset.xlsx' in your current directory\n","data = pd.read_excel('/kaggle/input/cust-churn-task/customer_churn_large_dataset.xlsx')\n","\n","# Define your features and target variable\n","X = data.drop('Churn', axis=1)  # Assuming 'churn' is the target variable\n","y = data['Churn']\n","\n","# Split the data into training, validation, and test sets\n","# Here, we use an 80-10-10 split, adjust percentages as needed\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","# Print the shapes of the resulting datasets to verify the split\n","print(\"Train set shape:\", X_train.shape)\n","print(\"Validation set shape:\", X_valid.shape)\n","print(\"Test set shape:\", X_test.shape)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-09-05T09:33:04.677781Z","iopub.status.busy":"2023-09-05T09:33:04.677436Z","iopub.status.idle":"2023-09-05T09:33:49.993420Z","shell.execute_reply":"2023-09-05T09:33:49.992232Z","shell.execute_reply.started":"2023-09-05T09:33:04.677751Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Top 5 most important features:\n","                      Feature  Importance\n","2                Monthly_Bill    0.317095\n","3              Total_Usage_GB    0.290777\n","0                         Age    0.188228\n","1  Subscription_Length_Months    0.147307\n","4                 Gender_Male    0.015698\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Load the dataset\n","data = pd.read_excel('/kaggle/input/cust-churn-task/customer_churn_large_dataset.xlsx')\n","\n","# Drop non-numeric columns like 'CustomerID' and 'Name'\n","data = data.drop(['CustomerID', 'Name'], axis=1)\n","\n","# Encode categorical variables like 'Gender' and 'Location' using one-hot encoding\n","data = pd.get_dummies(data, columns=['Gender', 'Location'], drop_first=True)\n","\n","# Define your features and target variable\n","X = data.drop('Churn', axis=1)  # Assuming 'Churn' is the target variable\n","y = data['Churn']\n","\n","# Split the data into training, validation, and test sets\n","# Here, we use an 80-10-10 split, adjust percentages as needed\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","# Initialize a Random Forest Classifier (or any tree-based model)\n","rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","# Train the classifier on the training data\n","rf_classifier.fit(X_train, y_train)\n","\n","# Get feature importances\n","feature_importances = rf_classifier.feature_importances_\n","\n","# Create a DataFrame to store feature names and their importances\n","feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n","\n","# Sort the features by importance in descending order\n","feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n","\n","# Print the top N most important features (e.g., top 5)\n","top_n = 5\n","top_features = feature_importance_df.head(top_n)\n","\n","# Print the top features\n","print(\"Top\", top_n, \"most important features:\")\n","print(top_features)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-09-05T09:33:49.995436Z","iopub.status.busy":"2023-09-05T09:33:49.995062Z","iopub.status.idle":"2023-09-05T09:36:47.242837Z","shell.execute_reply":"2023-09-05T09:36:47.241663Z","shell.execute_reply.started":"2023-09-05T09:33:49.995402Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Forest: Mean CV Accuracy = 0.5001\n","Logistic Regression: Mean CV Accuracy = 0.5045\n","Gradient Boosting: Mean CV Accuracy = 0.5026\n","\n","Best Model: Logistic Regression\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.linear_model import LogisticRegression\n","\n","# Load the dataset\n","data = pd.read_excel('/kaggle/input/cust-churn-task/customer_churn_large_dataset.xlsx')\n","\n","# Drop non-numeric columns like 'CustomerID' and 'Name'\n","data = data.drop(['CustomerID', 'Name'], axis=1)\n","\n","# Encode categorical variables like 'Gender' and 'Location' using one-hot encoding\n","data = pd.get_dummies(data, columns=['Gender', 'Location'], drop_first=True)\n","\n","# Define your features and target variable\n","X = data.drop('Churn', axis=1)  # Assuming 'Churn' is the target variable\n","y = data['Churn']\n","\n","# Split the data into training, validation, and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize different classifiers\n","classifiers = {\n","    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n","    'Logistic Regression': LogisticRegression(random_state=42),\n","    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n","}\n","\n","# Perform model selection and evaluation\n","results = {}\n","for classifier_name, classifier in classifiers.items():\n","    # Fit the model\n","    classifier.fit(X_train, y_train)\n","    \n","    # Evaluate the model using cross-validation (you can choose a different evaluation metric)\n","    cv_score = cross_val_score(classifier, X_train, y_train, cv=5, scoring='accuracy')\n","    \n","    # Store the mean cross-validation score\n","    results[classifier_name] = cv_score.mean()\n","\n","# Print the results\n","for classifier_name, cv_score in results.items():\n","    print(f'{classifier_name}: Mean CV Accuracy = {cv_score:.4f}')\n","\n","# Select the best model based on cross-validation results\n","best_model_name = max(results, key=results.get)\n","print(f'\\nBest Model: {best_model_name}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-05T09:36:47.245662Z","iopub.status.busy":"2023-09-05T09:36:47.245249Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Load the dataset\n","data = pd.read_excel('/kaggle/input/cust-churn-task/customer_churn_large_dataset.xlsx')\n","\n","# Drop non-numeric columns like 'CustomerID' and 'Name'\n","data = data.drop(['CustomerID', 'Name'], axis=1)\n","\n","# Encode categorical variables like 'Gender' and 'Location' using one-hot encoding\n","data = pd.get_dummies(data, columns=['Gender', 'Location'], drop_first=True)\n","\n","# Define your features and target variable\n","X = data.drop('Churn', axis=1)  # Assuming 'Churn' is the target variable\n","y = data['Churn']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize the Random Forest Classifier\n","rf_classifier = RandomForestClassifier(random_state=42)\n","\n","# Define a parameter grid for hyperparameter tuning\n","param_grid = {\n","    'n_estimators': [100, 200],\n","    'max_depth': [None, 10],\n","    'min_samples_split': [2, 5],\n","    'min_samples_leaf': [1, 2],\n","    'max_features': ['sqrt', 'log2'],\n","}\n","\n","\n","# Initialize GridSearchCV for hyperparameter tuning\n","grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n","\n","# Fit the grid search to the training data to find the best hyperparameters\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best hyperparameters from the grid search\n","best_params = grid_search.best_params_\n","\n","# Create a Random Forest Classifier with the best hyperparameters\n","best_rf_classifier = RandomForestClassifier(random_state=42, **best_params)\n","\n","# Train the best model on the training data\n","best_rf_classifier.fit(X_train, y_train)\n","\n","# Evaluate the best model on the test data\n","accuracy = best_rf_classifier.score(X_test, y_test)\n","\n","# Print the best hyperparameters and test accuracy\n","print(\"Best Hyperparameters:\", best_params)\n","print(\"Test Accuracy:\", accuracy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","from sklearn.model_selection import train_test_split\n","\n","# Assuming you have your data in X and y, split it into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Create and train a RandomForestClassifier (or another classifier)\n","best_rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n","best_rf_classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test data\n","y_pred = best_rf_classifier.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","\n","# Calculate precision\n","precision = precision_score(y_test, y_pred)\n","print(\"Precision:\", precision)\n","\n","# Calculate recall\n","recall = recall_score(y_test, y_pred)\n","print(\"Recall:\", recall)\n","\n","# Calculate F1-score\n","f1 = f1_score(y_test, y_pred)\n","print(\"F1-Score:\", f1)\n","\n","# Generate and print the confusion matrix\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from imblearn.over_sampling import SMOTE\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","# Load the dataset\n","data = pd.read_excel('/kaggle/input/cust-churn-task/customer_churn_large_dataset.xlsx')\n","\n","# Drop non-numeric columns like 'CustomerID' and 'Name'\n","data = data.drop(['CustomerID', 'Name'], axis=1)\n","\n","# Encode categorical variables like 'Gender' and 'Location' using one-hot encoding\n","data = pd.get_dummies(data, columns=['Gender', 'Location'], drop_first=True)\n","\n","# Define your features and target variable\n","X = data.drop('Churn', axis=1)  # Assuming 'Churn' is the target variable\n","y = data['Churn']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Apply SMOTE to balance the classes\n","smote = SMOTE(sampling_strategy='auto', random_state=42)\n","X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n","\n","# Initialize the Random Forest Classifier\n","rf_classifier = RandomForestClassifier(random_state=42)\n","\n","# Define a parameter grid for hyperparameter tuning\n","# Define a reduced parameter grid\n","param_grid = {\n","    'n_estimators': [100, 200],          # Reduced number of trees\n","    'max_depth': [None, 10],            # Reduced depth options\n","    'min_samples_split': [2, 5],       # Reduced min_samples_split options\n","    'min_samples_leaf': [1, 2],        # Reduced min_samples_leaf options\n","    'max_features': ['sqrt', 'log2'],  # Reduced max_features options\n","}\n","\n","# Rest of your code remains the same\n","\n","\n","# Initialize GridSearchCV for hyperparameter tuning\n","grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n","\n","# Fit the grid search to the resampled training data to find the best hyperparameters\n","grid_search.fit(X_train_resampled, y_train_resampled)\n","\n","# Get the best hyperparameters from the grid search\n","best_params = grid_search.best_params_\n","\n","# Create a Random Forest Classifier with the best hyperparameters\n","best_rf_classifier = RandomForestClassifier(random_state=42, **best_params)\n","\n","# Train the best model on the resampled training data\n","best_rf_classifier.fit(X_train_resampled, y_train_resampled)\n","\n","# Make predictions on the test data\n","y_pred = best_rf_classifier.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","\n","# Calculate precision\n","precision = precision_score(y_test, y_pred)\n","print(\"Precision:\", precision)\n","\n","# Calculate recall\n","recall = recall_score(y_test, y_pred)\n","print(\"Recall:\", recall)\n","\n","# Calculate F1-score\n","f1 = f1_score(y_test, y_pred)\n","print(\"F1-Score:\", f1)\n","\n","# Generate and print the confusion matrix\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from imblearn.over_sampling import SMOTE\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","import shap\n","import matplotlib.pyplot as plt\n","\n","# Load the dataset\n","data = pd.read_excel('/kaggle/input/cust-churn-task/customer_churn_large_dataset.xlsx')\n","\n","# Drop non-numeric columns like 'CustomerID' and 'Name'\n","data = data.drop(['CustomerID', 'Name'], axis=1)\n","\n","# Encode categorical variables like 'Gender' and 'Location' using one-hot encoding\n","data = pd.get_dummies(data, columns=['Gender', 'Location'], drop_first=True)\n","\n","# Define your features and target variable\n","X = data.drop('Churn', axis=1)  # Assuming 'Churn' is the target variable\n","y = data['Churn']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Apply SMOTE to balance the classes\n","smote = SMOTE(sampling_strategy='auto', random_state=42)\n","X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n","\n","# Initialize the Random Forest Classifier\n","rf_classifier = RandomForestClassifier(random_state=42)\n","\n","# Define a parameter grid for hyperparameter tuning\n","param_grid = {\n","    'n_estimators': [100, 200, 300],           # Number of trees in the forest\n","    'max_depth': [None, 10, 20, 30],           # Maximum depth of each tree\n","    'min_samples_split': [2, 5, 10],          # Minimum number of samples required to split an internal node\n","    'min_samples_leaf': [1, 2, 4],            # Minimum number of samples required to be at a leaf node\n","    'max_features': ['sqrt', 'log2'],         # Number of features to consider at each split\n","}\n","\n","# Initialize GridSearchCV for hyperparameter tuning\n","grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\n","\n","# Fit the grid search to the resampled training data to find the best hyperparameters\n","grid_search.fit(X_train_resampled, y_train_resampled)\n","\n","# Get the best hyperparameters from the grid search\n","best_params = grid_search.best_params_\n","\n","# Create a Random Forest Classifier with the best hyperparameters\n","best_rf_classifier = RandomForestClassifier(random_state=42, **best_params)\n","\n","# Train the best model on the resampled training data\n","best_rf_classifier.fit(X_train_resampled, y_train_resampled)\n","\n","# Make predictions on the test data\n","y_pred = best_rf_classifier.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","\n","# Calculate precision\n","precision = precision_score(y_test, y_pred)\n","print(\"Precision:\", precision)\n","\n","# Calculate recall\n","recall = recall_score(y_test, y_pred)\n","print(\"Recall:\", recall)\n","\n","# Calculate F1-score\n","f1 = f1_score(y_test, y_pred)\n","print(\"F1-Score:\", f1)\n","\n","# Generate and print the confusion matrix\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","\n","# SHAP values for feature importance\n","explainer = shap.TreeExplainer(best_rf_classifier)\n","shap_values = explainer.shap_values(X_test)\n","\n","# Summary plot of feature importance\n","shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n","plt.show()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":4}
